spark {
    app-name = "FileProcessing"
    master = "local[*]"
}

read-path {
 value ="src/main/resources/test.csv"
}

write-path {
 value ="src/main/resources/output.tsv"
}
# example configuration with amazon S3
#amazon-config{
#  read-auth {
#    auth-type {
#      name = "fs.amazon.account.auth.type"
#      value = "OAuth"
#    }
#  }
#  write-auth {
#      auth-type {
#        name = "fs.amazon.account.auth.type"
#        value = "OAuth"
#      }
#  }
#}